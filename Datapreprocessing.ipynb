{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e429c3-b1a9-4328-afd1-a56573cd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd06639-bf1a-45eb-a5d6-e185ac0455a0",
   "metadata": {},
   "source": [
    "Data Preprocessing: Data Preprocessing is a technique that is used to convert the raw data into a clean data set. It is one of steps in Data Preparation where raw unorganized data is converted to clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90b9b67-c7de-4e25-9e56-4860ca558172",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dfd40ab-102d-4507-a5e9-280cc79f2bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd152f6a-8985-4e12-8ab0-e908b5a97276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x) # prints all columns before last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48523a4c-c60b-4f33-b3df-8297e280a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y) # prints last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2974ed7-300a-4328-bb58-b83071a05f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(x[:, 1:3])\n",
    "x[:, 1:3] = imputer.transform(x[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cfd65ea-2711-410a-b405-da6341ea46bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n",
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(x) # fills mean value in the place of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e4388-1bff-4f84-a16f-7569d2c46dcc",
   "metadata": {},
   "source": [
    "#Encoding categorical data:\n",
    "Encoding categorical data is a process of converting categorical data into integer format so that the data with converted categorical values can be provided to the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a288212-78d3-40c0-9f98-b981427a8883",
   "metadata": {},
   "source": [
    "Encoding the Independent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bdecd0-3ac7-4907-b025-9ece2049dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the Independent variable\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb64a725-b9a8-4c20-a560-b3b912785cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x) # The country names are encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daee4d2-fcc3-475d-9696-2cd93c88f8fd",
   "metadata": {},
   "source": [
    "Encoding the Dependent Variable: A dependent variable that has just two possible values is usually encoded 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08649047-a674-43b7-8ea3-d735507b89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Dependent Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b46d300-0bb4-4056-9a51-832de8401a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y) # last column(Y or N) is encoded into 1's or 0's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94547c12-8f92-48cd-bcb7-2fdb3e6b417c",
   "metadata": {},
   "source": [
    "Splitting the dataset into the Training set and Test set: The phenomenon where a model performs really well on the data that we used to train it but it fails to generalise well to new, unseen data points is known to be overfitting. This might occur due to various reasons and then there is underfitting also.,  Therefore, we train the model using the training set and then apply the model to the test set. In this way, we can evaluate the performance of our model. For instance, if the training accuracy is extremely high while the testing accuracy is poor then this is a good indicator that the model is probably overfitted and viceversa for underfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e885648-4303-4618-938b-31e2c5b788e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2592d54a-7897-4292-8986-9c2f787717ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29992c8-cf28-4e65-8444-4f7f70f3c912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "292fda2d-8ca6-41b4-9728-d486c933a63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66eda0e1-60db-4b4d-a6c2-5544d7a35aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028f4e4-ca34-4f00-af03-4c973427c98d",
   "metadata": {},
   "source": [
    "Feature Scaling: Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b402678c-7151-4436-af65-1e46ce0a1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6213e3dc-b222-40c6-a201-76456b5b78c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77459667 -0.57735027  1.29099445 -0.19159184 -1.07812594]\n",
      " [-0.77459667  1.73205081 -0.77459667 -0.01411729 -0.07013168]\n",
      " [ 1.29099445 -0.57735027 -0.77459667  0.56670851  0.63356243]\n",
      " [-0.77459667 -0.57735027  1.29099445 -0.30453019 -0.30786617]\n",
      " [-0.77459667 -0.57735027  1.29099445 -1.90180114 -1.42046362]\n",
      " [ 1.29099445 -0.57735027 -0.77459667  1.14753431  1.23265336]\n",
      " [-0.77459667  1.73205081 -0.77459667  1.43794721  1.57499104]\n",
      " [ 1.29099445 -0.57735027 -0.77459667 -0.74014954 -0.56461943]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc174d84-15a2-4316-be4f-c44fb2cbc34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77459667  1.73205081 -0.77459667 -1.46618179 -0.9069571 ]\n",
      " [ 1.29099445 -0.57735027 -0.77459667 -0.44973664  0.20564034]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
